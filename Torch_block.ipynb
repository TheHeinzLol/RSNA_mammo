{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d56b0717-3ef5-4887-80d6-723635d2e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torcheval.metrics.functional import binary_confusion_matrix \n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdd66b1-7eb0-4467-95cc-c21887408541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics \n",
    "\n",
    "# tp = cm[1][1] \n",
    "# fp = cm[0][1] \n",
    "# fn = cm[1][0]\n",
    "# tn = cm[0][0]\n",
    "\n",
    "def precision(cm:np.ndarray) -> float:\n",
    "    tp = cm[1][1] \n",
    "    fp = cm[0][1]\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(cm:np.ndarray) -> float:\n",
    "    tp = cm[1][1] \n",
    "    fn = cm[1][0]\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def accuracy(cm:np.ndarray) -> float:\n",
    "    tp = cm[1][1]\n",
    "    tn = cm[0][0]\n",
    "    return (tp + tn) / cm.sum()\n",
    "\n",
    "def f_score(cm:np.ndarray, factor: int=1) -> float:\n",
    "    tp = cm[1][1]\n",
    "    fp = cm[0][1]\n",
    "    fn = cm[1][0]\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_score = (1 + factor ** 2) * ((precision * recall) / (factor * precision + recall))\n",
    "    return f_score\n",
    "\n",
    "# torch workflow\n",
    "def create_dataloader(dataset:str,\n",
    "                      batch_size: int=16,\n",
    "                      pin_memory: bool=True,\n",
    "                      shuffle: bool=True) -> torch.utils.data.DataLoader:\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        pin_memory=pin_memory\n",
    "    )    \n",
    "    \n",
    "    return loader   \n",
    "\n",
    "def train_step(model: nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: nn.Module,\n",
    "              optimizer: torch.optim.Optimizer,\n",
    "              device: str,\n",
    "              validation: bool=False) -> float:\n",
    "    loss = 0\n",
    "    if not validation:\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for X, y in loader:\n",
    "            \n",
    "            X, y = X.to(device), y.loat().to(device)\n",
    "    \n",
    "            logits = model(X)#.squeeze()\n",
    "            preds = logits.sigmoid().round()\n",
    "    \n",
    "            loss_batch = loss_fn(logits, y)\n",
    "            loss += loss_batch.item()\n",
    "            cm = binary_confusion_matrix(preds, y.long()).detach().cpu().numpy()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss_batch.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    if validation:\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "\n",
    "            for X, y in loader:\n",
    "                \n",
    "            X, y = X.to(device), y.float().to(device)\n",
    "\n",
    "            logits = model(X)#.squeeze()\n",
    "            preds = logints.sigmoid().round()\n",
    "\n",
    "            loss_batch = loss_fn(logits, y)\n",
    "            loss += loss_batch\n",
    "            cm = binary_confusion_matrix(preds, y.long()).detach().cpu().numpy()\n",
    "\n",
    "            \n",
    "    return loss, cm\n",
    "\n",
    "def freeze_model(model):\n",
    "  for param in model.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6701ae25-56ca-41bd-bdf4-5b5937f169fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download model and weights\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "transforms_auto = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1640d7-c0eb-4041-b29d-4ec5e24d6bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = '../png_roi/train_images'\n",
    "path_test = '../png_roi/test_images'\n",
    "\n",
    "dataset_train = ImageFolder(path_train, transform=transforms_auto)\n",
    "dataset_test = ImageFolder(path_test, transform=transforms_auto)\n",
    "\n",
    "loader_train = create_dataloader(dataset_train)\n",
    "loader_test = create_dataloader(dataset_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc8a46-e97e-42c8-aa02-53b23fd3a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(weights=weights)\n",
    "freeze_model(model)\n",
    "model.fc = nn.Linear(in_features=512, out_features=1, bias=True)\n",
    "model.to(device)\n",
    "\n",
    "lr = 3e-4\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb68fa6-4cfc-42ba-9887-3ee218fb41ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    print(f'Epoch #{epoch+1}')\n",
    "    \n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    train_cm = 0\n",
    "    test_cm = 0\n",
    "    \n",
    "    train_step_loss, train_step_cm = train_step(model, loader_train, loss_fn, optimizer, device)\n",
    "    test_step_loss, test_step_cm = train_step(model, loader_test, loss_fn, optimizer, device)\n",
    "\n",
    "    train_loss += train_step_loss\n",
    "    test_loss += test_step_loss\n",
    "    train_cm += train_step_cm\n",
    "    test_cm += test_step_cm\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Train loss: [{loss_train}] Test loss: [{loss_test}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe38215-de50-4b04-b492-e3f9c91d89f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
