{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3a452bd-ed56-48fc-9fc9-fc1093e90cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers import apply_windowing #\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cacdd79-bd61-4950-ad35-9fe5f7ce2d45",
   "metadata": {},
   "source": [
    "1) convert without resizing\n",
    "2) cut off empty space\n",
    "3) windowing\n",
    "4) resize to 1024x768 - HxW\n",
    "\n",
    "id_patient 59479 delete since it is of black shots only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a440c30a-7b9a-4b0d-8054-c5bf68576fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dicom = '../train_images/'\n",
    "path_png = '../png_roi/'\n",
    "images_dicom = glob.glob(path_dicom+ '*/*.dcm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0022ff-a2ac-47ad-a0ef-258707e58c02",
   "metadata": {},
   "source": [
    "### Step 1: converting dicom to grayscale png and apply windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0abb09ba-4b5f-4a83-9ec5-357b5eba8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dcm_to_png_windowing(path_image: str, \n",
    "                                 dir_save_to: str) -> None:\n",
    "    \n",
    "    id_patient, id_img = re.findall('(\\d+)', path_image)[-2:]\n",
    "    path_save = os.path.join(dir_save_to, id_patient) \n",
    "    \n",
    "    if os.path.isfile(os.path.join(path_save, id_img + '.png')):\n",
    "        pass\n",
    "    else:\n",
    "            \n",
    "        dicom = pydicom.dcmread(path_image)\n",
    "        \n",
    "        img = dicom.pixel_array\n",
    "        img = apply_windowing(img, dicom) #windowing itself\n",
    "        \n",
    "        img = (img - img.min()) / (img.max() - img.min()) # to [0;1] scale\n",
    "        \n",
    "        if dicom.PhotometricInterpretation == 'MONOCHROME1':\n",
    "            img = 1 - img\n",
    "        \n",
    "        img = (img * 255).astype(np.uint8)\n",
    "        \n",
    "        os.makedirs(path_save, exist_ok=True)\n",
    "        cv2.imwrite(os.path.join(path_save, id_img + '.png') , img)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b437b847-8532-4acc-b225-1c7631451b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████▌                | 28917/54706 [02:29<1:01:22,  7.00it/s]/tmp/ipykernel_8094/2905764910.py:15: RuntimeWarning: invalid value encountered in divide\n",
      "  img = (img - img.min()) / (img.max() - img.min()) # to [0;1] scale\n",
      "/tmp/ipykernel_8094/2905764910.py:20: RuntimeWarning: invalid value encountered in cast\n",
      "  img = (img * 255).astype(np.uint8)\n",
      " 78%|█████████████████████████▋       | 42684/54706 [3:37:40<1:01:18,  3.27it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# images_dicom[80]/[81]/[82] corrupted? start from [-26100:]\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m tqdm(images_dicom): \n\u001b[0;32m----> 4\u001b[0m     \u001b[43mconvert_dcm_to_png_windowing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_png\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m, in \u001b[0;36mconvert_dcm_to_png_windowing\u001b[0;34m(path_image, dir_save_to)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     dicom \u001b[38;5;241m=\u001b[39m pydicom\u001b[38;5;241m.\u001b[39mdcmread(path_image)\n\u001b[0;32m---> 12\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mdicom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpixel_array\u001b[49m\n\u001b[1;32m     13\u001b[0m     img \u001b[38;5;241m=\u001b[39m apply_windowing(img, dicom) \u001b[38;5;66;03m#windowing itself\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     img \u001b[38;5;241m=\u001b[39m (img \u001b[38;5;241m-\u001b[39m img\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m/\u001b[39m (img\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m img\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;66;03m# to [0;1] scale\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/KaggleV2/lib/python3.10/site-packages/pydicom/dataset.py:1955\u001b[0m, in \u001b[0;36mDataset.pixel_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1940\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpixel_array\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the pixel data as a :class:`numpy.ndarray`.\u001b[39;00m\n\u001b[1;32m   1943\u001b[0m \n\u001b[1;32m   1944\u001b[0m \u001b[38;5;124;03m    .. versionchanged:: 1.4\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[38;5;124;03m        :class:`numpy.ndarray`.\u001b[39;00m\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1955\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_pixel_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pixel_array)\n",
      "File \u001b[0;32m~/anaconda3/envs/KaggleV2/lib/python3.10/site-packages/pydicom/dataset.py:1512\u001b[0m, in \u001b[0;36mDataset.convert_pixel_data\u001b[0;34m(self, handler_name)\u001b[0m\n\u001b[1;32m   1510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_pixel_data_using_handler(handler_name)\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1512\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_pixel_data_without_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/KaggleV2/lib/python3.10/site-packages/pydicom/dataset.py:1604\u001b[0m, in \u001b[0;36mDataset._convert_pixel_data_without_handler\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m available_handlers:\n\u001b[1;32m   1603\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1604\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_pixel_data_conversion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1605\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1606\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/envs/KaggleV2/lib/python3.10/site-packages/pydicom/dataset.py:1631\u001b[0m, in \u001b[0;36mDataset._do_pixel_data_conversion\u001b[0;34m(self, handler)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Do the actual data conversion using the given handler.\"\"\"\u001b[39;00m\n\u001b[1;32m   1629\u001b[0m \u001b[38;5;66;03m# Use the handler to get a 1D numpy array of the pixel data\u001b[39;00m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;66;03m# Will raise an exception if no pixel data element\u001b[39;00m\n\u001b[0;32m-> 1631\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pixeldata\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pixel_array \u001b[38;5;241m=\u001b[39m reshape_pixel_array(\u001b[38;5;28mself\u001b[39m, arr)\n\u001b[1;32m   1634\u001b[0m \u001b[38;5;66;03m# Some handler/transfer syntax combinations may need to\u001b[39;00m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;66;03m#   convert the color space from YCbCr to RGB\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/KaggleV2/lib/python3.10/site-packages/pydicom/pixel_data_handlers/pylibjpeg_handler.py:327\u001b[0m, in \u001b[0;36mget_pixeldata\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m    324\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(expected_len, pixel_dtype(ds))\n\u001b[1;32m    326\u001b[0m generate_offsets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, expected_len, frame_len)\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame, offset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(generate_frames(ds, \u001b[38;5;28;01mFalse\u001b[39;00m), generate_offsets):\n\u001b[1;32m    328\u001b[0m     arr[offset:offset \u001b[38;5;241m+\u001b[39m frame_len] \u001b[38;5;241m=\u001b[39m frame\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/anaconda3/envs/KaggleV2/lib/python3.10/site-packages/pydicom/pixel_data_handlers/pylibjpeg_handler.py:263\u001b[0m, in \u001b[0;36mgenerate_frames\u001b[0;34m(ds, reshape)\u001b[0m\n\u001b[1;32m    260\u001b[0m bits_allocated \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mint\u001b[39m, ds\u001b[38;5;241m.\u001b[39mBitsAllocated)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m generate_pixel_data_frame(ds\u001b[38;5;241m.\u001b[39mPixelData, nr_frames):\n\u001b[0;32m--> 263\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpixel_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    266\u001b[0m         tsyntax \u001b[38;5;129;01min\u001b[39;00m [JPEG2000, JPEG2000Lossless]\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mAPPLY_J2K_CORRECTIONS\n\u001b[1;32m    268\u001b[0m     ):\n\u001b[1;32m    269\u001b[0m         param \u001b[38;5;241m=\u001b[39m get_j2k_parameters(frame)\n",
      "File \u001b[0;32m~/anaconda3/envs/KaggleV2/lib/python3.10/site-packages/libjpeg/utils.py:180\u001b[0m, in \u001b[0;36mdecode_pixel_data\u001b[0;34m(arr, ds, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported (0028,0004) Photometric Interpretation \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, no \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolour transformation will be applied\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    177\u001b[0m     )\n\u001b[1;32m    178\u001b[0m     transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/KaggleV2/lib/python3.10/site-packages/libjpeg/utils.py:97\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(stream, colour_transform, reshape)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     arr \u001b[38;5;241m=\u001b[39m stream\n\u001b[0;32m---> 97\u001b[0m status, out, params \u001b[38;5;241m=\u001b[39m \u001b[43m_libjpeg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolour_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m status \u001b[38;5;241m=\u001b[39m status\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m code, msg \u001b[38;5;241m=\u001b[39m status\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::::\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# images_dicom[80]/[81]/[82] corrupted? start from [-26100:]\n",
    "\n",
    "for image in tqdm(images_dicom): \n",
    "    convert_dcm_to_png_windowing(image, path_png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce6c20-7128-48ce-8510-b3a8a4e38255",
   "metadata": {},
   "source": [
    "### Cutting off empty regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186bda2e-1b96-4315-ba24-00d5e1513c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(image: str, \n",
    "             dir_save_to: str) -> None:\n",
    "    \n",
    "    X = cv2.imread(image)\n",
    "    \n",
    "    # Some images have narrow exterior \"frames\" that complicate selection of the main data. Cutting off the frame\n",
    "    X = X[5:-5, 5:-5]\n",
    "    \n",
    "    # regions of non-empty pixels\n",
    "    output= cv2.connectedComponentsWithStats((X > 20).astype(np.uint8)[:, :, 0], 8, cv2.CV_32S) # connectivity 4 insted of 8 may give us more regions which we don't want\n",
    "\n",
    "    # output[0] is a number of labels\n",
    "    # output[1] is matrix of labels\n",
    "    # output[2] is stat matrix\n",
    "    # output[4] is centroid matrix\n",
    "    \n",
    "    # stats.shape == (N, 5), where N is the number of regions, 5 dimensions correspond to:\n",
    "    # left, top, width, height, area_size\n",
    "    stats = output[2]\n",
    "    \n",
    "    # finding max area which always corresponds to the breast data. \n",
    "    idx = stats[1:, 4].argmax() + 1 # starting with 1 because largest region will be the whole picture\n",
    "    x1, y1, w, h = stats[idx][:4]\n",
    "    x2 = x1 + w\n",
    "    y2 = y1 + h\n",
    "    \n",
    "    # cutting out the breast data\n",
    "    X_roi = X[y1: y2, x1: x2]\n",
    "    \n",
    "    patient_id, id_img = re.findall('(\\d+)', image)[-2:]\n",
    "    cv2.imwrite(f'{dir_save_to}/{patient_id}/{id_img}.png', X_roi[:, :, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b52d24e-836d-4b3d-907f-989802bdde95",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_png = glob.glob(path_png+'*/*.png')\n",
    "\n",
    "for image in tqdm(images_png):\n",
    "    crop_img(image, path_png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c145ac06-e040-4766-b348-d8f8ff88d7a4",
   "metadata": {},
   "source": [
    "### Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01bb414-322e-4a65-92e7-3b228ca08240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image: str, \n",
    "                 dir_save_to: str, \n",
    "                 size: tuple[int,int]=(768, 1024)) -> None:\n",
    "\n",
    "    img = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, dsize=size)\n",
    "    \n",
    "    patient_id, id_img = re.findall('(\\d+)', image)[-2:]\n",
    "    cv2.imwrite(f'{path_png}/{patient_id}/{id_img}.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ca8a1-88f8-4eef-8d3f-7fa2ee35f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in tqdm(images_png):\n",
    "    resize_image(image, path_png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349392a2-2d69-4ecf-889d-1e1ef685736e",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c87a0cb-6bb0-4517-b4be-3b7bf8e295a2",
   "metadata": {},
   "source": [
    "Later, we may use this DataFrame for getting auxiliary predictions, but there are some columns that will not be available in test DataFrame. I don't know if we will use tabular data at all, nor do I know if we will make use of train only columns yet. It would be best to try all 3 methods: img only; auxiliary predictions on tabular data without train only columns; auxiliary predictions with train only columns, - but hardware and time are limiting factors for me now. Anyway, I will save list of train only columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb6219-4a80-4e02-8cf4-b992ae4b4a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "train_only_cols = ['density', 'biopsy', 'invasive', 'BIRADS', 'difficult_negative_case']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560cf70c-d5ee-42da-b2c5-677491aa89da",
   "metadata": {},
   "source": [
    "Not like we need this df for now, but it won't hurt to take a look at data anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e5cc4-6ce6-46e7-9882-09df0d2754a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1933c01-31e5-4cd9-b0a1-9d892cbc7593",
   "metadata": {},
   "source": [
    "For now, we only need image and patient ids and respective target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be0c7b3-3829-49be-8724-6c0d68bfbc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['cancer']\n",
    "X = df.drop(columns=['cancer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29053c9c-c958-498a-b758-d4cd64d889e6",
   "metadata": {},
   "source": [
    "This split will be applied on images only and not on patients, so images from one patient folder may be assigned to different splits. I don't think that there is a leakage: sure thing is that if patient has cancer on one breast, chances are higher for them to have it on another breast too, but we won't be giving our ANN information on what patient is particular image assigned to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b865f238-c801-49d3-aa2a-7bdc360bc46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873da83c-117c-48b8-bd5f-9e184e090d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_images(X: pd.DataFrame, \n",
    "                 y: pd.Series, \n",
    "                 dir_source: str, \n",
    "                 dir_destination: str) -> None:\n",
    "    \n",
    "    '''This function is used to sort images to folders with name of respective class, so later we can use ImageFolder to create train and test datasets.\n",
    "    Inputs:\n",
    "        X: train or test dataset.\n",
    "        y: train or test series of same length as X, containing target variables, i.e. \"cancer\" column of original DataFrame.\n",
    "        dir_source: directory containing all folders with patient id.\n",
    "        dir_destination: directory to move train or test data to, e.g. train_images_folder.\n",
    "    Output: None\n",
    "        Function will create \"dir_destination/class/patient_id\" path and move respective pictures there'''\n",
    "    \n",
    "\n",
    "    assert len(X) == len(y), \"X and y must have same amount of elements. Check shapes of X and y.\"\n",
    "\n",
    "    # Moving images from DataFrame to their class folders.\n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        id_patient = str(X.iloc[i]['patient_id'])\n",
    "        id_image = str(X.iloc[i]['image_id']) + '.png'\n",
    "        cancer = str(y.iloc[i])\n",
    "    \n",
    "        path_source = os.path.join(dir_source, id_patient, id_image)\n",
    "        path_destination = os.path.join(dir_destination, cancer, id_patient)\n",
    "        \n",
    "        if os.path.isfile(path_source):\n",
    "            os.makedirs(path_destination, exist_ok=True)\n",
    "            shutil.move(path_source, os.path.join(path_destination, id_image))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    #Remove empty folders\n",
    "    for folder in os.listdir(dir_source): \n",
    "        try:\n",
    "            os.removedirs(os.path.join(dir_source, folder))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd79fd8-8dca-4287-b0f9-bc0fdc83b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_source = '../png_roi' \n",
    "path_train_png = '../png_roi/train_images' #train_images_png\n",
    "path_test_png = '../png_roi/test_images' #test_images_png\n",
    "\n",
    "split_images(X_train, y_train, dir_source=dir_source, dir_destination=path_train_png)\n",
    "split_images(X_test, y_test, dir_source=dir_source, dir_destination=path_test_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204eda7-70db-4f8c-aa47-938df3588ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
