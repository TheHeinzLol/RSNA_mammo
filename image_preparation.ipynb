{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3a452bd-ed56-48fc-9fc9-fc1093e90cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers import apply_windowing #\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cacdd79-bd61-4950-ad35-9fe5f7ce2d45",
   "metadata": {},
   "source": [
    "1) convert without resizing\n",
    "2) cut off empty space\n",
    "3) windowing\n",
    "4) resize to 1024x768 - HxW\n",
    "5) data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a440c30a-7b9a-4b0d-8054-c5bf68576fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dicom = '../train_images/'\n",
    "path_png = '../png_roi/'\n",
    "images_dicom = glob.glob(path_dicom+ '*/*.dcm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0022ff-a2ac-47ad-a0ef-258707e58c02",
   "metadata": {},
   "source": [
    "### Step 1: converting dicom to grayscale png and apply windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0abb09ba-4b5f-4a83-9ec5-357b5eba8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dcm_to_png_windowing(path_image: str, \n",
    "                                 dir_save_to: str) -> None:\n",
    "    \n",
    "    id_patient, id_img = re.findall('(\\d+)', path_image)[-2:]\n",
    "    path_save = os.path.join(dir_save_to, id_patient) \n",
    "    \n",
    "    if os.path.isfile(os.path.join(path_save, id_img + '.png')):\n",
    "        pass\n",
    "    else:\n",
    "            \n",
    "        dicom = pydicom.dcmread(path_image)\n",
    "        \n",
    "        img = dicom.pixel_array\n",
    "        img = apply_windowing(img, dicom) #windowing itself\n",
    "        \n",
    "        img = (img - img.min()) / (img.max() - img.min()) # to [0;1] scale\n",
    "        \n",
    "        if dicom.PhotometricInterpretation == 'MONOCHROME1':\n",
    "            img = 1 - img\n",
    "        \n",
    "        img = (img * 255).astype(np.uint8)\n",
    "        \n",
    "        os.makedirs(path_save, exist_ok=True)\n",
    "        cv2.imwrite(os.path.join(path_save, id_img + '.png') , img)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b437b847-8532-4acc-b225-1c7631451b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/54706 [00:00<?, ?it/s]/tmp/ipykernel_3814/1532111195.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  img = (img - img.min()) / (img.max() - img.min()) # to [0;1] scale\n",
      "/tmp/ipykernel_3814/1532111195.py:21: RuntimeWarning: invalid value encountered in cast\n",
      "  img = (img * 255).astype(np.uint8)\n",
      "100%|██████████████████████████████████| 54706/54706 [00:01<00:00, 30481.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for image in tqdm(images_dicom): \n",
    "    convert_dcm_to_png_windowing(image, path_png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce6c20-7128-48ce-8510-b3a8a4e38255",
   "metadata": {},
   "source": [
    "### Cutting off empty regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "186bda2e-1b96-4315-ba24-00d5e1513c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(image: str, \n",
    "             dir_save_to: str) -> None:\n",
    "    \n",
    "    X = cv2.imread(image)\n",
    "    \n",
    "    # Some images have narrow exterior \"frames\" that complicate selection of the main data. Cutting off the frame\n",
    "    X = X[5:-5, 5:-5]\n",
    "    \n",
    "    # regions of non-empty pixels\n",
    "    output= cv2.connectedComponentsWithStats((X > 20).astype(np.uint8)[:, :, 0], 8, cv2.CV_32S) # connectivity 4 insted of 8 may give us more regions which we don't want\n",
    "\n",
    "    # output[0] is a number of labels\n",
    "    # output[1] is matrix of labels\n",
    "    # output[2] is stat matrix\n",
    "    # output[4] is centroid matrix\n",
    "    \n",
    "    # stats.shape == (N, 5), where N is the number of regions, 5 dimensions correspond to:\n",
    "    # left, top, width, height, area_size\n",
    "    stats = output[2]\n",
    "    patient_id, id_img = re.findall('(\\d+)', image)[-2:]\n",
    "\n",
    "    try:\n",
    "        # finding max area which always corresponds to the breast data. \n",
    "        idx = stats[1:, 4].argmax() + 1 # starting with 1 because largest region will be the whole picture\n",
    "    except:\n",
    "        return int(patient_id)\n",
    "        \n",
    "    idx = stats[1:, 4].argmax() + 1\n",
    "    x1, y1, w, h = stats[idx][:4]\n",
    "    x2 = x1 + w\n",
    "    y2 = y1 + h\n",
    "    \n",
    "    # cutting out the breast data\n",
    "    X_roi = X[y1: y2, x1: x2]\n",
    "    \n",
    "    cv2.imwrite(f'{dir_save_to}/{patient_id}/{id_img}.png', X_roi[:, :, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef69318f-0fe3-43b0-bd88-646508892253",
   "metadata": {},
   "source": [
    "While trying out the function above, I found that there are corrupted files which are pitch black, and they contain only one segment. Consequently, `idx = stats[1:, 4].argmax() + 1` throws an error because it calls the second element when there is only one. We will identify those files and delete them.\n",
    "\n",
    "I thought that windowing might cause this, since but I checked it and there were no changes. For those who are not familiar with windowing, it essentially makes pixels brighter or darker based on a threshold. It could be that all the pixels are below this threshold, resulting in all of them turning black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f43c4-94c2-48ba-bf4b-185e2dcf35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_png = glob.glob(path_png+'*/*.png')\n",
    "corrupted = set()\n",
    "for image in tqdm(images_png):\n",
    "    corrupted.append(crop_img(image, path_png))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c145ac06-e040-4766-b348-d8f8ff88d7a4",
   "metadata": {},
   "source": [
    "### Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01bb414-322e-4a65-92e7-3b228ca08240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image: str, \n",
    "                 dir_save_to: str, \n",
    "                 size: tuple[int,int]=(768, 1024)) -> None:\n",
    "\n",
    "    img = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, dsize=size)\n",
    "    \n",
    "    patient_id, id_img = re.findall('(\\d+)', image)[-2:]\n",
    "    cv2.imwrite(f'{path_png}/{patient_id}/{id_img}.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ca8a1-88f8-4eef-8d3f-7fa2ee35f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in tqdm(images_png):\n",
    "    resize_image(image, path_png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349392a2-2d69-4ecf-889d-1e1ef685736e",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c87a0cb-6bb0-4517-b4be-3b7bf8e295a2",
   "metadata": {},
   "source": [
    "Later, we may use this DataFrame to obtain auxiliary predictions, but some columns will not be available in the test DataFrame. I am uncertain whether we will use tabular data or if we will utilize columns exclusive to the training set. It would be ideal to try all three methods: using images only, making auxiliary predictions on tabular data excluding training-only columns, and making auxiliary predictions with training-only columns. However, hardware and time constraints currently limit me. Nevertheless, I will save a list of the training-only columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb6219-4a80-4e02-8cf4-b992ae4b4a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "train_only_cols = ['density', 'biopsy', 'invasive', 'BIRADS', 'difficult_negative_case']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560cf70c-d5ee-42da-b2c5-677491aa89da",
   "metadata": {},
   "source": [
    "Although we do not currently need this DataFrame, it would be beneficial to examine the data regardless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e5cc4-6ce6-46e7-9882-09df0d2754a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1933c01-31e5-4cd9-b0a1-9d892cbc7593",
   "metadata": {},
   "source": [
    "Currently, we require only the image and patient IDs along with their respective target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be0c7b3-3829-49be-8724-6c0d68bfbc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['cancer']\n",
    "X = df.drop(columns=['cancer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29053c9c-c958-498a-b758-d4cd64d889e6",
   "metadata": {},
   "source": [
    "This split will be applied only to images, not to patients; thus, images from a single patient folder may be assigned to different splits. I don't believe there is leakage: it is true that if a patient has cancer in one breast, the chances are higher for the other breast to be affected as well. However, we will not provide our ANN with information about which patient a particular image is assigned to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b865f238-c801-49d3-aa2a-7bdc360bc46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873da83c-117c-48b8-bd5f-9e184e090d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_images(X: pd.DataFrame, \n",
    "                 y: pd.Series, \n",
    "                 dir_source: str, \n",
    "                 dir_destination: str) -> None:\n",
    "    \n",
    "    '''This function is used to sort images to folders with name of respective class, so later we can use ImageFolder to create train and test datasets.\n",
    "    Inputs:\n",
    "        X: train or test dataset.\n",
    "        y: train or test series of same length as X, containing target variables, i.e. \"cancer\" column of original DataFrame.\n",
    "        dir_source: directory containing all folders with patient id.\n",
    "        dir_destination: directory to move train or test data to, e.g. train_images_folder.\n",
    "    Output: None\n",
    "        Function will create \"dir_destination/class/patient_id\" path and move respective pictures there'''\n",
    "    \n",
    "\n",
    "    assert len(X) == len(y), \"X and y must have same amount of elements. Check shapes of X and y.\"\n",
    "\n",
    "    # Moving images from DataFrame to their class folders.\n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        id_patient = str(X.iloc[i]['patient_id'])\n",
    "        id_image = str(X.iloc[i]['image_id']) + '.png'\n",
    "        cancer = str(y.iloc[i])\n",
    "    \n",
    "        path_source = os.path.join(dir_source, id_patient, id_image)\n",
    "        path_destination = os.path.join(dir_destination, cancer, id_patient)\n",
    "        \n",
    "        if os.path.isfile(path_source):\n",
    "            os.makedirs(path_destination, exist_ok=True)\n",
    "            shutil.move(path_source, os.path.join(path_destination, id_image))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    #Remove empty folders\n",
    "    for folder in os.listdir(dir_source): \n",
    "        try:\n",
    "            os.removedirs(os.path.join(dir_source, folder))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd79fd8-8dca-4287-b0f9-bc0fdc83b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_source = '../png_roi' \n",
    "path_train_png = '../png_roi/train_images' #train_images_png\n",
    "path_test_png = '../png_roi/test_images' #test_images_png\n",
    "\n",
    "split_images(X_train, y_train, dir_source=dir_source, dir_destination=path_train_png)\n",
    "split_images(X_test, y_test, dir_source=dir_source, dir_destination=path_test_png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa81341-8c91-471d-bb1e-b69e010bc543",
   "metadata": {},
   "source": [
    "### Data Augmentation with Albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd115b9f-f1a5-4064-b1f6-7232ffc21aa4",
   "metadata": {},
   "source": [
    "I've been experimenting with various augmentation options and found that these make a fine mix of affine and pixel-wise transformations. These include rotating, flipping, cropping, and adjusting the brightness and contrast of images. Although these can also be applied to test data, as they do not crop out any parts of an image, ensuring that no areas containing cancer are lost, I will eliminate contrast tuning to ensure that cancerous parts do not blend with healthy tissue. Since the data is highly imbalanced, I will create multiple augmented copies of each positive class image to upsample it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124098b7-c58d-4191-b11c-3d7ea1cfbc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.Rotate (limit=180, interpolation=1, border_mode=4, value=None, mask_value=None, rotate_method='largest_box', crop_border=False, p=0.6),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomGridShuffle (grid=(np.random.randint(1,8), np.random.randint(1,8)), p=0.25),\n",
    "    A.PixelDropout (dropout_prob=0.3, per_channel=False, drop_value=0, mask_drop_value=None, p=0.4),\n",
    "    A.RandomBrightnessContrast (brightness_limit=[-0.3,0.3], contrast_limit=[-0.2,0.2], brightness_by_max=True, p=0.4),\n",
    "\n",
    "])\n",
    "show_augmentation(transform, images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5af4445-b552-40a4-b0a8-67f91ffd096a",
   "metadata": {},
   "source": [
    "Take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8714ded-7123-49f9-8502-9e30bc67ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_augmentation(transform: A,\n",
    "                      image: str) -> None:\n",
    "    rows = 3\n",
    "    cols = 2\n",
    "    \n",
    "    img_orig = Image.open(image)\n",
    "    img_orig = np.array(img_orig)\n",
    "    img_transformed = transform(image=img_orig)['image']\n",
    "\n",
    "    fig = plt.figure(figsize=(10,15))\n",
    "    fig.add_subplot(rows, cols, 1)\n",
    "    plt.imshow(img_orig, cmap='gray')\n",
    "    plt.axis(False)\n",
    "    \n",
    "    for i in range(2, cols* rows +1):\n",
    "        fig.add_subplot(rows, cols, i)\n",
    "        plt.imshow(transform(image=img_orig)['image'], cmap='gray')\n",
    "        plt.axis(False)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a1607b-d570-4feb-a296-eefc3c919734",
   "metadata": {},
   "source": [
    "Now, let's augment and see what we've got. We only augment train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c47f9d1-6f3a-414b-bf7e-f6df873379de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_images(image: str,\n",
    "                   dir_dest: str) -> None:\n",
    "        \n",
    "    class_label, id_patient, id_img = re.findall('(\\d+)',image)\n",
    "        \n",
    "    img_orig = Image.open(image)\n",
    "    img_orig = np.array(img_orig)\n",
    "\n",
    "    path_save = os.path.join(dir_dest, class_label, id_patient)\n",
    "    os.makedirs(path_save, exist_ok=True)\n",
    "    \n",
    "    if int(class_label): #if cancer: make 3 augmented copies\n",
    "        for i in range(3): \n",
    "            img_transformed = transform(image=img_orig)['image']\n",
    "            cv2.imwrite(f'{path_save}/{id_img}_augmented_{i}.png', img_transformed)\n",
    "    else:\n",
    "        img_transformed = transform(image=img_orig)['image']\n",
    "        cv2.imwrite(f'{path_save}/{id_img}_augmented.png', img_transformed)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951aeea9-0035-4efa-85de-10462b34bd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = glob.glob(path_train_png + '/*/*/*.png')\n",
    "for image in tqdm(train_images):\n",
    "    augment_images(image, path_train_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d5a561-6488-4b29-bdc1-1832d0dcaa2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
